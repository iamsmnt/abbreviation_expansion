{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsmnt/test1/blob/master/abbreviation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Q5DjAJF_1kRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5_ZvyM_2QGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5e533489-5f25-4f21-87c2-d3fedcf322ce"
      },
      "cell_type": "code",
      "source": [
        "corpus = input()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The quick brown fox jumps into the water and wait for the crocodile to come and sees that the water current suddenly increases and both the crocodile and fox starts flowing through the water\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P46GQ8Mq1zRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LanguageNgramModel:\n",
        "    \"\"\" \n",
        "    The model remembers and predicts which letters follow which.\n",
        "    Constructor parameters:\n",
        "        order - number of characters the model remembers, or n-1\n",
        "        smoothing - the number, added to each counter for stability\n",
        "        recursive - weight of the model of one order less\n",
        "    Learned parameters:\n",
        "        counter_ - storage of n-grams, as dict of counters  \n",
        "        vocabulary_ - set of characters that the model knows\n",
        "    \"\"\"\n",
        "    def __init__(self, order=1, smoothing=1.0, recursive=0.001):\n",
        "        self.order = order\n",
        "        self.smoothing = smoothing\n",
        "        self.recursive = recursive\n",
        "    \n",
        "    def fit(self, corpus):\n",
        "        \"\"\" Estimate freqency of all n-grams in the text\n",
        "        parameters:\n",
        "            corpus - a text string \n",
        "        \"\"\"\n",
        "        self.counter_ = defaultdict(lambda: Counter())\n",
        "        self.vocabulary_ = set()\n",
        "        for i, token in enumerate(corpus[self.order:]):\n",
        "            context = corpus[i:(i+self.order)]\n",
        "            self.counter_[context][token] += 1\n",
        "            self.vocabulary_.add(token)\n",
        "            print(i,self.counter_)\n",
        "        self.vocabulary_ = sorted(list(self.vocabulary_))\n",
        "        if self.recursive > 0 and self.order > 0:\n",
        "            self.child_ = LanguageNgramModel(self.order-1, self.smoothing, self.recursive)\n",
        "            self.child_.fit(corpus)\n",
        "        print(self.counter_)\n",
        "        print(self.vocabulary_)\n",
        "            \n",
        "    def get_counts(self, context):\n",
        "        \"\"\" Estimate frequency of all symbols that may follow the context\n",
        "        Parameters:\n",
        "            context - text string (only the last self.order chars matter)\n",
        "        Returns: \n",
        "            freq - vector of letter conditional frequencies, as pandas.Series\n",
        "        \"\"\"\n",
        "        if self.order:\n",
        "            local = context[-self.order:]\n",
        "        else:\n",
        "            local = ''\n",
        "        freq_dict = self.counter_[local]\n",
        "        freq = pd.Series(index=self.vocabulary_)\n",
        "        for i, token in enumerate(self.vocabulary_):\n",
        "            freq[token] = freq_dict[token] + self.smoothing\n",
        "        if self.recursive > 0 and self.order > 0:\n",
        "            child_freq = self.child_.get_counts(context) * self.recursive\n",
        "            freq += child_freq\n",
        "        return freq\n",
        "    \n",
        "    def predict_proba(self, context):\n",
        "        \"\"\" Estimate probability of all symbols that may follow the context\n",
        "        Parameters:\n",
        "            context - text string (only the last self.order chars matter)\n",
        "        Returns: \n",
        "            freq - vector of letter conditional frequencies, as pandas.Series\n",
        "        \"\"\"\n",
        "        counts = self.get_counts(context)\n",
        "        return counts / counts.sum()\n",
        "    def single_log_proba(self, context, continuation):\n",
        "        \"\"\" Estimate log probability of the certain continuation of the context\n",
        "        Parameters:\n",
        "            context - text string, known beginning of the phrase\n",
        "            continuation - text string, its hypothetical end\n",
        "        Returns: \n",
        "            result - a float, log of probability\n",
        "        \"\"\"\n",
        "        result = 0.0\n",
        "        for token in continuation:\n",
        "            result += np.log(self.predict_proba(context)[token])\n",
        "            context += token\n",
        "        return result\n",
        "    \n",
        "    def single_proba(self, context, continuation):\n",
        "        \"\"\" Estimate probability of the certain continuation of the context\n",
        "        Parameters:\n",
        "            context - text string, known beginning of the phrase\n",
        "            continuation - text string, its hypothetical end\n",
        "        Returns: \n",
        "            result - a float, probability\n",
        "        \"\"\"\n",
        "        return np.exp(self.single_log_proba(context, continuation))\n",
        "            \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnD565VS5GtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0f047c64-c9d7-4914-baf6-1a575b8ab83f"
      },
      "cell_type": "code",
      "source": [
        "lang_model = LanguageNgramModel(1)\n",
        "lang_model.fit(' abracadabra ')\n",
        "print(lang_model.predict_proba(' bra'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0.181777\n",
            "a    0.091297\n",
            "b    0.272529\n",
            "c    0.181686\n",
            "d    0.181686\n",
            "r    0.091025\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHigwdsL5ZZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "592f739a-ed39-4044-9917-6b4550564270"
      },
      "cell_type": "code",
      "source": [
        "lang_model.fit('mississippi')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'m': 1})})\n",
            "1 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'m': 1, 'i': 1})})\n",
            "2 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'m': 1, 'i': 1, 's': 1})})\n",
            "3 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'s': 2, 'm': 1, 'i': 1})})\n",
            "4 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'i': 2, 's': 2, 'm': 1})})\n",
            "5 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'s': 3, 'i': 2, 'm': 1})})\n",
            "6 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'s': 4, 'i': 2, 'm': 1})})\n",
            "7 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'s': 4, 'i': 3, 'm': 1})})\n",
            "8 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'s': 4, 'i': 3, 'm': 1, 'p': 1})})\n",
            "9 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'s': 4, 'i': 3, 'p': 2, 'm': 1})})\n",
            "10 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'i': 4, 's': 4, 'p': 2, 'm': 1})})\n",
            "defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c812f28>, {'': Counter({'i': 4, 's': 4, 'p': 2, 'm': 1})})\n",
            "['i', 'm', 'p', 's']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LqwaXeW452d0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8cb3ef4c-6862-41da-936b-6ac56f5498f4"
      },
      "cell_type": "code",
      "source": [
        "lang_model.fit('dandelion')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 1})})\n",
            "1 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 1, 'a': 1})})\n",
            "2 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 1, 'a': 1, 'n': 1})})\n",
            "3 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 2, 'a': 1, 'n': 1})})\n",
            "4 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 2, 'a': 1, 'n': 1, 'e': 1})})\n",
            "5 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 2, 'a': 1, 'n': 1, 'e': 1, 'l': 1})})\n",
            "6 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 2, 'a': 1, 'n': 1, 'e': 1, 'l': 1, 'i': 1})})\n",
            "7 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 2, 'a': 1, 'n': 1, 'e': 1, 'l': 1, 'i': 1, 'o': 1})})\n",
            "8 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884d290ea0>, {'': Counter({'d': 2, 'n': 2, 'a': 1, 'e': 1, 'l': 1, 'i': 1, 'o': 1})})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1sKy8bP958oT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1b0a74d5-be40-4d0d-f314-5634d6228e0d"
      },
      "cell_type": "code",
      "source": [
        "lang_model.fit('cat')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c7f4ea0>, {'': Counter({'c': 1})})\n",
            "1 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c7f4ea0>, {'': Counter({'c': 1, 'a': 1})})\n",
            "2 defaultdict(<function LanguageNgramModel.fit.<locals>.<lambda> at 0x7f884c7f4ea0>, {'': Counter({'c': 1, 'a': 1, 't': 1})})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wfwQrUQm8ddv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ecdaea6d-65fc-4bdc-8b32-89502ea44358"
      },
      "cell_type": "code",
      "source": [
        "s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]\n",
        "d = defaultdict(list)\n",
        "for k, v in s:\n",
        "  d[k].append(v)\n",
        "  print(d.items())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_items([('yellow', [1])])\n",
            "dict_items([('yellow', [1]), ('blue', [2])])\n",
            "dict_items([('yellow', [1, 3]), ('blue', [2])])\n",
            "dict_items([('yellow', [1, 3]), ('blue', [2, 4])])\n",
            "dict_items([('yellow', [1, 3]), ('blue', [2, 4]), ('red', [1])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vQcKQWES_2Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}